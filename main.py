#!/usr/bin/env python
import sys
import requests
# import warnings
from pydantic import BaseModel
from typing import List, Optional
from dotenv import load_dotenv
from fastapi import FastAPI, Body, UploadFile, File, Form
import textwrap
from updateCrew.crew_update import update_crew
from Load.load import _load_yaml
import cx_Oracle
import json
import os
import logging
import uuid
import traceback
import re
from agent_logger.logger_config import setup_logger
from app_config import config_loader
from typing import Any, Dict
import json
import uuid
import importlib
import yaml
from fastapi.responses import StreamingResponse
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import ConversationChain
from langchain.memory.chat_message_histories import RedisChatMessageHistory
import asyncio
import sys
# import AgentFunction
from fastapi.middleware.cors import CORSMiddleware
import time
from concurrent.futures import ProcessPoolExecutor
import datetime as dt
from langchain.schema import AIMessage
import redis.asyncio as aioredis
import time
import uuid
import pandas as pd
from fastapi import HTTPException
from io import BytesIO
from fastapi.encoders import jsonable_encoder
from Mcp.mcp_client import McpClient
from langchain.memory import ChatMessageHistory
from langchain_ollama import ChatOllama

setup_logger()
load_dotenv()

app = FastAPI()
executor = ProcessPoolExecutor(max_workers=os.cpu_count() or 1)
origins = ['https://aiml-perf.excelacom.in', 'https://g7perf-aiml.excelacomcloud.net',
           'https://dev-g7-product.excelacom.in', 'https://sit-g7-product.excelacom.in',
           'https://mlaa.excelacomcloud.com', 'https://devqa1-g7-product.excelacom.in',
           'https://devqa2-g7-product.excelacom.in', 'https://plm-g7-product.excelacom.in',
           'https://regression-g7-product.excelacom.in', 'https://la-g7-product.excelacom.in',
           'https://demo-g7-product.excelacom.in', 'https://demo-panther.excelacomcloud.net',
           'https://mlaa-poc.excelacomcloud.com','http://exinl3420-103:3000','http://exinl3430-43:3000','https://dev-mlaa-g7-product.excelacomcloud.net',]

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

LOGGER = logging.getLogger(__name__)
agents_config = 'E:/agents/agents.yaml'
tasks_config = 'E:/agents/tasks.yaml'

#BACATALOG DB credentials
app_catalog_dev_qa1_username=config_loader.get('app_catalog_username')
app_catalog_dev_qa1_password=config_loader.get('app_catalog_password')
app_catalog_dev_qa1_service_name=config_loader.get('app_catalog_service_name')
app_catalog_dev_qa1_host=config_loader.get('app_catalog_host')
app_catalog_dev_qa1_port=config_loader.get('app_catalog_port')

#AI_ML_DEVPS DB credentials
dev_ml_username=config_loader.get('ml_username')
dev_ml_password=config_loader.get('ml_password')
dev_ml_service_name=config_loader.get('ml_service_name')
dev_ml_host=config_loader.get('ml_catalog_host')
dev_ml_port=config_loader.get('ml_port')

#Ollama URL
ollama_endpoint_url=config_loader.get('ollama_endpoint_url')
extract_url=config_loader.get('extract_url')

#Redis connection URL
redis_url = redis_url = "redis://10.90.3.51:6379"

#Input format for calling run function
class InputModel(BaseModel):
    payload: Any
    selected_agent: List[str]

#Input format for calling create_agent
class AgentTaskTool(BaseModel):
    agentId: Any

#Input format for calling run_agent function
class RootId(BaseModel):
    agentId: Any
    data: Any

#To receive output from custom_tool.py to run function
class FinalOutput(BaseModel):
    finalOutput: Any

#Input format for conversational Agent api
class conversationInputModel(BaseModel):
    input: str
    session_id: str

#Input format for conversational Agent api
class ValidateConversationInputModel(BaseModel):
    input: str
    session_id: str
    url_redis: str
# Replace with inputs you want to test with, it will automatically
# interpolate any tasks and agents information

class RedisMessages(BaseModel):
    sessionId: str

@app.post("/centuryAgents/startUpLoading/")
def startupLoading():
    try:
        LOGGER.info("startupLoading Method - Starts")
        crew_file = "E:/agents/crew.py"  # crew.py file path
        filename = r"E:/agents/AgentFunction.py" # File where all code generated by generator_task is present or code generated must be updated in this file.
        with open(filename, 'a+', encoding='utf-8') as file:
            file.seek(0) # To point from stating index of file
            methods_content = file.read() # Reads the AgentFunction file content
        try:
            with open(crew_file, "r") as file:
                crew_content = file.readlines() #Reads the crew file content
        except FileNotFoundError:
            LOGGER.error("Crew.py not found")
            return
        
        # Agents.yaml file
        agent_file_path = "E:/agents/agents.yaml"
        # Read content from the file
        # Check if the file exists
        yaml_text=""
        if os.path.exists(agent_file_path):
            with open(agent_file_path, "r") as file:
                yaml_text = file.read()
        else:
            # Create the file (empty) if it doesn't exist
            with open(agent_file_path, "w") as file:
                pass
        agents_pattern = r"^(\w+_(?:generator|executor)):" # To filter all agents from agents.yaml.
        existing_agents = set(re.findall(agents_pattern, yaml_text, re.MULTILINE)) # To filter all agents from agents.yaml.

        # Tasks.yaml file
        task_file_path = "E:/agents/tasks.yaml"
        # Check if the file exists
        if os.path.exists(task_file_path):
            # Read content from the file
            with open(task_file_path, "r") as file:
                yaml_text = file.read()
        else:
            # Create the file (empty) if it doesn't exist
            with open(task_file_path, "w") as file:
                pass

        tasks_pattern = r"^(\w+_(?:generator_task|executor_task)):" # To filter all tasks from tasks.yaml.
        existing_tasks = set(re.findall(tasks_pattern, yaml_text, re.MULTILINE)) # To filter all tasks from tasks.yaml.
        existing_methods = set(re.findall(r'def\s+(\w+)\s*\(', "".join(methods_content))) # Extracts all function names presents in AgentFunction.py file.
        connection = cx_Oracle.connect(user=dev_ml_username, password=dev_ml_password, dsn=cx_Oracle.makedsn(dev_ml_host,dev_ml_port,service_name=dev_ml_service_name)) # Connection to oracle database
        cursor = connection.cursor()
        # Select all rows
        """
        Select agent name, config type(Agents: Agent_generator Agent_executor, 
        Tasks: Agent_generator_task, Agent_executor_task, custom code), 
        config data(actual data to be put inside yaml file or .py file), 
        method name(for typing python function from agent name since agent name may have spaces between its data which will give error in python code)
        """
        agents_data=config_loader.get('agents_data')
        LOGGER.info("agents_data query")
        LOGGER.info(agents_data)
        cursor.execute(agents_data)
        previous_name = None
        row_count = 0
        # Process each row
        for agent_name, config_type, config_data, method_name in cursor:
            # Read blob content
            if agent_name == previous_name:
        # Increment the count if the agent_name is the same
                row_count += 1
            else:
                # If an entire agent name has finished iterating, check if the row count is greater than 0
                if previous_name is not None and row_count > 0:
                    # Call the function with the updated name format
                    method_check = previous_name.replace(" ", "_")
                    response=update_crew(method_check)  # Call the custom function with formatted name. This function is used to update crew.py and custom_tool.py
                    if response=="Success":
                        LOGGER.info("Agent created successfully")
                    else:
                        LOGGER.info("Error creating Agent")   
                # Reset for the new agent_name
                previous_name = agent_name
                row_count = 1  # Start counting the new agent name

            blob_content = config_data.read() if hasattr(config_data, 'read') else config_data
            # Decode bytes to string
            code_str = blob_content.decode("utf-8")
            # Define filename based on agent or config type
            if config_type != 'custom_logic':
                #formatted_str=format_task_string(code_str)
                #code_str=formatted_str
                # Logic for removing unwanted data and alignment of data before writing in yaml files.
                # Step 1: Clean up the string by replacing unwanted characters with needed characters
                    if(config_type == 'tasks_generator_yaml' or config_type == 'tasks_executor_yaml'):
                        code_str = code_str.replace("{", "").replace("}", "").replace('"', '')
                        code_str = code_str.replace(",", "\n   ")

                        # Step 2: Split into lines
                        lines = code_str.split("\n")
                        # Known keys for tasks.yaml to match
                        known_keys = {"description", "expected_output", "agent"}
                        formatted_str = ""
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                            # Split line by the first occurrence of ":"
                            if ":" in line:
                                key, value = line.split(":", 1)
                                key = key.strip()
                                value = value.strip()
                                if key==method_name and formatted_str.split().count(method_name)<1:
                                    formatted_str+=f"{key}: {value}\n"
                                elif key in known_keys:
                                    formatted_str += f"  {key}: {value}\n"
                                else:
                                    # Treat unknown keys or values as standalone lines
                                    formatted_str += f"    {line}\n"
                            else:
                                formatted_str += f"    {line}\n"

                        code_str = formatted_str

                    elif(config_type == 'agents_generator_yaml' or config_type == 'agents_executor_yaml'):
                        code_str = code_str.replace("{", "").replace("}", "").replace('"', '')
                        code_str = code_str.replace(",", "\n   ")
                        # Step 2: Split into lines
                        lines = code_str.split("\n")
                        formatted_str = ""
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                            if line.endswith(":"):  # Main keys like Addition_generator:
                                formatted_str += line + "\n"
                            else:
                                if ":" in line:
                                    key, value = line.split(":", 1)
                                    key = key.strip()
                                    value = value.strip()
                                    # Wrap the value if too long (> 80 chars)
                                    wrapped_value = textwrap.fill(value, width=80,
                                                                initial_indent='  ' + key + ": ",
                                                                subsequent_indent='    ')
                                    formatted_str += wrapped_value + "\n"
                                else:
                                    # Unexpected lines (normally shouldn't happen)
                                    formatted_str += "    " + line + "\n"
                        code_str=formatted_str
                
                # Output the result
            if config_type == 'custom_logic':
                filename = "AgentFunction.py" # For python code(generated by LLM) to save
                # Check if the file exists, if not, create it
                if not os.path.exists(filename):
                    with open(filename, 'a', encoding='utf-8') as f:
                        pass  # Create an empty file
                    
                with open(filename, 'a+', encoding='utf-8') as file:
                    if method_name not in existing_methods:
                        file.write(code_str)
                        file.write("\n")

            elif config_type == 'agents_generator_yaml' or config_type == 'agents_executor_yaml':
                filename = "E:/agents/agents.yaml"
                # Check if the file exists, if not, create it
                if not os.path.exists(filename):
                    with open(filename, 'a', encoding='utf-8') as f:
                        pass  # Create an empty file
                
                # Write to file  
                if method_name in existing_agents:
                    pass
                else:
                    with open(filename, "a", encoding="utf-8") as f:
                        f.write(code_str)
                        f.write("\n")
                        
            elif config_type == 'tasks_generator_yaml' or config_type == 'tasks_executor_yaml':
                filename = "E:/agents/tasks.yaml"
                # Read existing file content first
                # Check if the file exists, if not, create it
                if not os.path.exists(filename):
                    with open(filename, 'w', encoding='utf-8') as f:
                        pass
                
                if method_name in existing_tasks:
                    pass           
                    # Write to file
                else:
                    with open(filename, "a", encoding="utf-8") as f:
                        f.write(code_str)
                        f.write("\n")


        if previous_name is not None and row_count > 0:
            # Call the function for the last agent name present in oracle db
            method_check = previous_name.replace(" ", "_")
            response=update_crew(method_check)
            if response=="Success":
                LOGGER.info("Agent created successfully")
            else:
                LOGGER.info("Error creating Agent")
        connection.commit()
        cursor.close()
        connection.close()
        LOGGER.info("startupLoading Method - Ends")
        return "Data updated successfully in respective files."
    except Exception as e:
        LOGGER.error(traceback.format_exc())
        return "Error occurred while updating data in files."



@app.post("/centuryAgents/run/")
def run(input_data: InputModel):
    try:
        FinalOutput.finalOutput="" # To receive output from custom_tool.py to here(main.py)
        LOGGER.info("Run method Method - Starts")
        global shared_payload
        shared_payload=input_data.payload
        global request_dict # To send request_dict from main.py to custom_tool.py
        request_dict = shared_payload
        LOGGER.info('Request Dict = ')
        LOGGER.info(request_dict)
        inputs = {
            'input': input_data.payload
        }
        
        agents = []
        tasks = []
        import AgentFunction
        if 'AgentFunction' in sys.modules:
            del sys.modules['AgentFunction']
            LOGGER.info("AgentFunction has been removed from system modules.")

        AgentFunction = importlib.import_module('AgentFunction')
        LOGGER.info("AgentFunction After Reload")
        for agent in input_data.selected_agent:
            # If the AgentFunction already has given agent_function, then only executor_task must be run in the agents. Else generator_task abd executor task must be run. Same goes for agents also.    
            if hasattr(AgentFunction, agent) and callable(getattr(AgentFunction, agent)):
                if len(input_data.selected_agent)==1:
                    result = getattr(AgentFunction, agent)("", request_dict.get(agent))
                    return result
  
                agents.append(f"{agent}_executor")
                tasks.append(f"{agent}_executor_task")
            else:
                agents.append(f"{agent}_generator")
                agents.append(f"{agent}_executor")

                tasks.append(f"{agent}_generator_task")
                tasks.append(f"{agent}_executor_task")

        import crew
        importlib.reload(crew) # Updating crew to new content written in crew.py
        from crew import CodeGeneration         
        CodeGeneration(
            selected_agents=agents,
            selected_tasks=tasks
        ).crew().kickoff(inputs=inputs) # Starts the actual agent(crewai) flow.
        LOGGER.info("Run method Method - Ends")
        return FinalOutput.finalOutput  
    except Exception as e:
        LOGGER.error(traceback.format_exc())
    
@app.post("/centuryAgents/runAgent/")
def run_agent(data: RootId):
    try:
        LOGGER.info("Run agent Method - Starts")
        #Connecting to BA catalog DB.
        connection = cx_Oracle.connect(user=app_catalog_dev_qa1_username, password=app_catalog_dev_qa1_password, dsn=cx_Oracle.makedsn(app_catalog_dev_qa1_host,app_catalog_dev_qa1_port,service_name=app_catalog_dev_qa1_service_name))
        cursor = connection.cursor()     
        agent_query=config_loader.get('agent_query')
        agent_query=agent_query.format(data.agentId,data.agentId)
        LOGGER.info("Agent_Query")
        LOGGER.info(agent_query)
        #Above sql query for extracting agent_name and expected_output from oracle db.
        cursor.execute(agent_query)
        rows = cursor.fetchall()
        LOGGER.info("Agent_Query Output")
        LOGGER.info(rows)
        agents_names=[]
        method_names=[]
        json_payloads=dict()
        for i in range(0,len(rows)):
            agents_names.append(rows[i][0])
            method_name=agents_names[i].replace(" ","_") # For writing in yaml files and Agentfunction.py since agent_name has spaces, it will give error.
            method_names.append(method_name)
            user_request = data.data
            json_payloads[method_name] = user_request
        distinct_methods=set(method_names)
        method_names=list(distinct_methods)
        agentFields = InputModel(payload=json_payloads, selected_agent=method_names) # Converting data to proper JSON for running the agents.
        agent_response_data=run(agentFields)
        agent_response = {
            "status": "success",
            "statusCode": 200,
            "responseMessage": ""
        }

        LOGGER.info(agent_response_data)
        LOGGER.info(type(agent_response_data))
        
        try:
            LOGGER.info("Inside try")
            if '{' in agent_response_data:
                LOGGER.info("Inside if(try)")
                json_response=json.loads(agent_response_data)
            else:
                LOGGER.info("Inside else(try)")
                json_response=str(agent_response_data)
        except Exception as e1:
            LOGGER.info("Inside except")
            json_response=str(agent_response_data)

        #Formatting the agent output.
        agent_response['responseMessage'] = json_response
        LOGGER.info("Agent Response")
        LOGGER.info(agent_response)
        connection.commit()
        cursor.close()
        connection.close()
        LOGGER.info("Run agent Method - Ends")
        return agent_response
    except Exception as e:
        LOGGER.error(traceback.format_exc())
        agent_response = {
            "status": "Failure",
            "statusCode": 500,
            "responseMessage": "Failure"
        }
        return agent_response
        

@app.post("/centuryAgents/createAgent/")

def create_agent(data: AgentTaskTool):
    """
    Author : Gnana Bharathi S
    Created On : 05/05/2025
    This method is for creating agents.
    """ 
    try:
        LOGGER.info("Create agent Method - Starts")
        #Connecting to BA catalog DB.
        connection_app = cx_Oracle.connect(user=app_catalog_dev_qa1_username, password=app_catalog_dev_qa1_password, dsn=cx_Oracle.makedsn(app_catalog_dev_qa1_host,app_catalog_dev_qa1_port,service_name=app_catalog_dev_qa1_service_name))
        cursor_app = connection_app.cursor()
        agents_data = dict()
        tasks_data = dict()
        agent_query=config_loader.get('agent_query')
        if isinstance(data.agentId, list):
            ids_str = ",".join(str(id_) for id_ in data.agentId)
            agent_query=agent_query.format(ids_str,ids_str)
        else:
            agent_query=agent_query.format(data.agentId,data.agentId)

        LOGGER.info("Agent_Query")
        LOGGER.info(agent_query)
        #Above sql query for extracting agent_name and expected_output from oracle db.
        cursor_app.execute(agent_query) # Runs the sql query
        rows = cursor_app.fetchall() # Fetches the data from this sql query
        cursor_app.close()
        connection_app.close()
        LOGGER.info("Agent_Query Output")
        LOGGER.info(rows)
        agents_names=[]
        expected_outputs=[]
        goals=[]
        llm_models=[]
        api_names=[]
        for i in range(0,len(rows)):
            agent_name = rows[i][0]
            expected_output = rows[i][1]
            goal=rows[i][2]
            llm_model=rows[i][3]
            api_name=rows[i][4]
            agents_names.append(agent_name)
            if(expected_output==None):
                expected_outputs.append("")
            else:
                expected_outputs.append(expected_output)
            goals.append(goal)
            llm_models.append(llm_model)
            api_names.append(api_name)
        agents_count=len(agents_names)
        for i in range(0,agents_count):
            agent_name=agents_names[i]
            method_name=agent_name.replace(" ","_")
            if method_name + "_generator" in agents_data.keys():
                LOGGER.info("Agent with the name {0} already present".format(agent_name))
            else:
                url_query=config_loader.get('url_query')
                url_query=url_query.format(api_names[i])
                LOGGER.info("URL_Query")
                LOGGER.info(url_query)
                connection_app = cx_Oracle.connect(user=app_catalog_dev_qa1_username, password=app_catalog_dev_qa1_password, dsn=cx_Oracle.makedsn(app_catalog_dev_qa1_host,app_catalog_dev_qa1_port,service_name=app_catalog_dev_qa1_service_name))
                cursor_app = connection_app.cursor()
                cursor_app.execute(url_query) # Runs the sql query
                rows = cursor_app.fetchall() # Fetches the data from this sql query
                cursor_app.close()
                connection_app.close()
                LOGGER.info("URL_Query_Output")
                LOGGER.info(rows)
                dsn_data="cx_Oracle.makedsn({0},{1},service_name={2})".format(app_catalog_dev_qa1_host,app_catalog_dev_qa1_port,app_catalog_dev_qa1_service_name)
                if(len(rows)==0):
                    url=""
                    static_prompt=config_loader.get('no_url_prompt')
                    static_prompt=static_prompt.format(method_name,method_name,method_name,method_name, method_name, method_name,app_catalog_dev_qa1_username,app_catalog_dev_qa1_password,dsn_data)
                else:
                    url_data=rows[0]
                    if(isinstance(url_data, tuple)):
                        url=url_data[0]
                        method = url_data[1]
                    else:
                        url=url_data
                        method = 'POST'
                        
                    static_prompt=config_loader.get('static_prompt')
                    static_prompt=static_prompt.format(method_name,method_name,method_name,method_name, method_name, method_name,app_catalog_dev_qa1_username,app_catalog_dev_qa1_password,dsn_data,method)
                models = config_loader.get('models')
                dict_models=json.loads(models)
                model_name=""
                for key, value in dict_models.items():
                    if llm_models[i] in value:
                        model_name=key+llm_models[i]
                        break
                #Agents.yaml data
                agents_data.update({
                    method_name + "_generator": {
                        "role": "Senior Python Developer",
                        "goal": "Write a python code based on the instruction given in task",
                        "backstory": "You're a seasoned Python Developer with experience in building robust software solutions, specializing in automation, data analysis, and scalable application development.",
                        "max_iter": 1,
                        "max_retry_limit": 0,
                        "llm": model_name
                    },
                    method_name + "_executor": {
                        "role": "Python Script Runner",
                        "goal": "Use {0} tool for executing the python code.".format(method_name),
                        "backstory": "You're a senior python code executor with experience in streamline Python code execution",
                        "max_iter": 1,
                        "max_retry_limit": 0,
                        "llm": model_name
                    }
                })

                LOGGER.info("Expected_outputs[i]")
                LOGGER.info(expected_outputs[i])
                LOGGER.info("Type(Expected_outputs[i])")
                LOGGER.info(type(expected_outputs[i]))

                LOGGER.info("URL")
                LOGGER.info(url)
                LOGGER.info("Type(url)")
                LOGGER.info(type(url))

                LOGGER.info("Static_Prompt")
                LOGGER.info(static_prompt)
                LOGGER.info("Type(static_prompt)")
                LOGGER.info(type(static_prompt))

                #Tasks.yaml data
                tasks_data.update({
                    method_name + "_generator_task": {
                        "description": "Write a python code alone to achieve the expected output.",
                        "expected_output": expected_outputs[i] + ' ' + url + ' ' + static_prompt,
                        "agent": method_name + "_generator"
                    },
                    method_name + "_executor_task": {
                        "description": "Python code execution framework that can handle dynamically generated code",
                        "expected_output": "Task that uses {0} tool for executing the python code.".format(method_name),
                        "agent": method_name + "_executor"
                    }
                })

                #Below connection is for connecting to AI_ML_DEVPS database. In this crewai_config table is present.
                connection_dev = cx_Oracle.connect(user=dev_ml_username, password=dev_ml_password, dsn=cx_Oracle.makedsn(dev_ml_host,dev_ml_port,service_name=dev_ml_service_name))
                cursor_dev = connection_dev.cursor()
                check=config_loader.get('check_duplicates')
                sel=check.format(agent_name)
                LOGGER.info("check_duplicates_query")
                LOGGER.info(sel)
                cursor_dev.execute(sel)
                rows = cursor_dev.fetchall()
                LOGGER.info("check_duplicates_query output")
                LOGGER.info(rows)
                connection_dev.commit() # Commits so that rollback option cannot be used to undo delete operation.
                cursor_dev.close()
                connection_dev.close()
                if(len(rows)>0):
                    LOGGER.info("Agent {0} already exists".format(agent_name))
                    connection_dev = cx_Oracle.connect(user=dev_ml_username, password=dev_ml_password, dsn=cx_Oracle.makedsn(dev_ml_host,dev_ml_port,service_name=dev_ml_service_name))
                    cursor_dev = connection_dev.cursor()
                    delete_query=config_loader.get('delete_query').format(agent_name) # Extracting query to delete agents data from oracle db.
                    LOGGER.info("Delete Query")
                    LOGGER.info(delete_query)
                    cursor_dev.execute(delete_query) # This sql query deletes the rows of agents data
                    connection_dev.commit() # Commits so that rollback option cannot be used to undo delete operation.
                    cursor_dev.close()
                    connection_dev.close()
                    
                    delete_names=[]
                    i=agent_name
                    i=i.replace(" ","_")
                    agent_generator=i+"_generator"
                    agent_executor=i+"_executor"
                    task_generator=i+"_generator_task"
                    task_executor=i+"_executor_task"
                    delete_names.append(agent_generator)
                    delete_names.append(agent_executor)
                    delete_names.append(task_generator)
                    delete_names.append(task_executor)
                    
                    file_paths = [
                        "E:/agents/agents.yaml",
                        "E:/agents/tasks.yaml",
                    ]

                    for file_path in file_paths:
                        if os.path.exists(file_path):
                            with open(file_path, 'r') as file:
                                try:
                                    data = yaml.safe_load(file) or {}
                                except yaml.YAMLError as e:
                                    LOGGER.error("Error while reading yaml files")
                                    data = {}

                            # Remove the specified agent names if present
                            for agent in delete_names:
                                if agent in data:
                                    del data[agent]

                            # Write back the updated data
                            with open(file_path, 'w') as file:
                                if(len(data)<1):
                                    file.write("")
                                else:
                                    yaml.dump(data, file, sort_keys=False)
                    
                    # Below part of code clears all content in AgentFunction.py to insert updated python code by deleting existing python code.
                    code_file="E:/agents/AgentFunction.py"
                                # Read original code
                    with open(code_file, 'r') as file:
                        code = file.read()

                    # Build a regex pattern to remove each function in agent_names
                    func_name=agent_name
                    func_name=func_name.replace(" ","_")
                    # pattern = rf"^def\s+{func_name}\s*\(.*?\):\n(?:[ \t]+.*\n)*"
                    # pattern = rf"""
                    #     (?:(?:^[ \t]*@[^\n]+\n)*)
                    #     ^[ \t]*def\s+{func_name}\s*\(.*?\):
                    #     (?:\n(?:[ \t]+.*|\s*)?)*
                    # """
                    # pattern = "^\s*def\s+{func_name}\(.*\):.*?(?=(\n\s*def \w|\Z))"
                    pattern = rf'^\s*def\s+{func_name}\s*\(.*\):([\r\n]+[ \t]+.*)*$'
 
                    code = re.sub(pattern, '', code, flags=re.MULTILINE)

                    # Write the updated code back to the file
                    with open(code_file, 'w') as file:
                        file.write(code)

                connection_dev = cx_Oracle.connect(user=dev_ml_username, password=dev_ml_password, dsn=cx_Oracle.makedsn(dev_ml_host,dev_ml_port,service_name=dev_ml_service_name))
                cursor_dev = connection_dev.cursor()
                sql = config_loader.get('insert_query')
                LOGGER.info("Insert_Query")
                LOGGER.info(sql)
                method_name=agent_name.replace(" ","_")
                agent_key = method_name + "_generator"
                agent_dict = agents_data[agent_key]
                agent_str = json.dumps(agent_dict)
                formatted_str = f"{agent_key}:\n\t{agent_str}"
                cursor_dev.execute(sql, (agent_name, "agents_generator_yaml", formatted_str.encode(),method_name+"_generator"))
                #Above code is for converting data to a specific format so that it can be inserted as BLOB in crewai_config table.
                #The same thing is done for agents generator and executor and tasks generator and executor.
                
                method_name=agent_name.replace(" ","_")
                agent_key = method_name + "_executor"
                agent_dict = agents_data[agent_key]
                agent_str = json.dumps(agent_dict)
                formatted_str = f"{agent_key}:\n\t{agent_str}"
                cursor_dev.execute(sql, (agent_name, "agents_executor_yaml", formatted_str.encode(),method_name+"_executor"))

                method_name=agent_name.replace(" ","_")
                task_key = method_name + "_generator_task"
                task_dict = tasks_data[task_key]
                task_str = json.dumps(task_dict)
                formatted_str = f"{task_key}:\n\t{task_str}"
                cursor_dev.execute(sql, (agent_name, "tasks_generator_yaml",formatted_str.encode(),method_name+"_generator_task"))
            
                method_name=agent_name.replace(" ","_")
                task_key = method_name + "_executor_task"
                task_dict = tasks_data[task_key]
                task_str = json.dumps(task_dict)
                formatted_str = f"{task_key}:\n\t{task_str}"
                cursor_dev.execute(sql, (agent_name, "tasks_executor_yaml", formatted_str.encode(),method_name+"_executor_task"))

                connection_dev.commit()
                cursor_dev.close()
                connection_dev.close()
        output=startupLoading()
        agents = []
        tasks = []
        inputs = {
            'input': ""
        }
        LOGGER.info(agents_names)
        for i in range(0,agents_count):
            agent_name=agents_names[i]
            method_name=agent_name.replace(" ","_")
            LOGGER.info("Inside For Loop for agents name")
            LOGGER.info(agent_name)
            LOGGER.info(method_name)
            agents.append(f"{method_name}_generator")
            tasks.append(f"{method_name}_generator_task")
            LOGGER.info(agents)
            LOGGER.info(tasks)

            import crew
            importlib.reload(crew) # Updating crew to new content written in crew.py
            from crew import CodeGeneration         
            CodeGeneration(
                selected_agents=agents,
                selected_tasks=tasks
            ).crew().kickoff(inputs=inputs)
        LOGGER.info("Create agent Method - Ends")
        return "Data inserted in Oracle DB(Table crewai_config) successfully"

    except Exception as e:
        LOGGER.error(traceback.format_exc())
        return "Error while inserting data in Table crewai_config"

@app.get("/centuryAgents/listAgent/")
def list_agent():
    
    """
    Author : Gnana Bharathi S
    Created On : 23/04/2025
    This method is for displaying agent names present.
    """
    
    try:
        LOGGER.info("List agent Method - Starts")
        agents_data = _load_yaml(agents_config)
        filtered_agents = [key for key in agents_data.keys() if not key.endswith("_generator") and not key.endswith("_executor")]
        LOGGER.info("List agent Method - Ends")
        return filtered_agents
    except Exception as e:
        LOGGER.error(traceback.format_exc())

def train():
    """
    Train the crew for a given number of iterations.
    """
    inputs = {
        "topic": "AI LLMs"
    }
    try:
        from crew import CodeGeneration
        CodeGeneration().crew().train(n_iterations=int(sys.argv[1]), filename=sys.argv[2], inputs=inputs)

    except Exception as e:
        LOGGER.error(traceback.format_exc())

def replay():
    """
    Replay the crew execution from a specific task.
    """
    try:
        from crew import CodeGeneration
        CodeGeneration().crew().replay(task_id=sys.argv[1])

    except Exception as e:
        LOGGER.error(traceback.format_exc())

def test():
    """
    Test the crew execution and returns the results.
    """
    inputs = {
        "topic": "AI LLMs"
    }
    try:
        from crew import CodeGeneration
        CodeGeneration().crew().test(n_iterations=int(sys.argv[1]), openai_model_name=sys.argv[2], inputs=inputs)

    except Exception as e:
        LOGGER.error(traceback.format_exc())

@app.get("/centuryAgents/validationApi/")
def rag_collections():
    try:
        LOGGER.info("Validation Method - Starts")
 
        response = {
            "status": 'Success',
            "session_id": uuid.uuid4()
        }
 
        LOGGER.info("Validation Method - Ends")
        return response
    except Exception as e:
        LOGGER.error(traceback.format_exc())

def transform_row_to_json(row):
    try:
        common_params = row.dropna().to_dict()
        common_params['SERVICE NUMBER'] = common_params['STANDARD OFFERING'] + " " + common_params['SERVICE NUMBER']
        product_query = "select * from contract_pricing_reference where standard_offering = '{}'".format(row["STANDARD OFFERING"])
        connection_dev = cx_Oracle.connect(user=dev_ml_username, password=dev_ml_password, dsn=cx_Oracle.makedsn(dev_ml_host,dev_ml_port,service_name=dev_ml_service_name))
        cursor = connection_dev.cursor()
        cursor.execute(product_query)
        rows = cursor.fetchall()
        columns = [col[0] for col in cursor.description]
        df = pd.DataFrame(rows, columns=columns)
        product_spec = df['PRODUCT_SPECIFICATION'].unique()
        contract_field_list = df['CONTRACT_FIELD'].unique()
        updated_common_params = {k: v for k, v in common_params.items() if k not in contract_field_list}
        child_products = {}
        for prod_spec in product_spec:
            filtered_df = df[df["PRODUCT_SPECIFICATION"] == prod_spec]
            child_products[prod_spec.upper()] = {
                row1["CONTRACT_FIELD"]: str(row[row1["CONTRACT_FIELD"]])
                for _, row1 in filtered_df.iterrows()
            }
            child_products[prod_spec.upper()].update(updated_common_params)
        child_products['commonParams'] = common_params
        result = {
            "childProducts": child_products,
            **common_params
        }
        return result
    except:
        LOGGER.error(traceback.format_exc())

async def ocr_extraction_excel(files):
    try:
        LOGGER.info("OCR Extraction from Files - Starts")
        all_sheet_names = []
        file_result = {}
        for file in files:
            # Validate file type
            if not file.filename.endswith((".xlsx", ".xls")):
                raise HTTPException(
                    status_code=400,
                    detail=f"Invalid file type for {file.filename}. Please upload only Excel files."
                )

            # Read file content
            contents = await file.read()
            excel_data = pd.read_excel(BytesIO(contents), sheet_name=None)  # Read all sheets

            # Convert all sheets to dict
            list_1 = ['Guidelines', 'Offering']
            list_2 = ['Site', 'Serviceability', 'Contact']
            list_3 = ['Offerings', 'Locations', 'ServiceGroup']
            all_sheet_names=list(excel_data.keys())
            LOGGER.info(f"All sheet names: {all_sheet_names}")
            for sheet_name, df in excel_data.items():
                if list_1 == all_sheet_names:
                    for sheet in all_sheet_names:
                        LOGGER.info(f"Sheet: {sheet}")
                        if sheet == "Offering" and sheet_name == 'Offering':
                            file_result[sheet_name] = [transform_row_to_json(r) for _, r in df.iterrows()]
                        else:
                            LOGGER.info(f"else sheet: {sheet}")
                            pass
                elif list_2 == all_sheet_names or list_3 == all_sheet_names:
                    if sheet_name == "Locations" or sheet_name in list_2:
                        file_result[sheet_name] = df.fillna("").to_dict(orient="records")

            encoded = jsonable_encoder(file_result)
     
        LOGGER.info("OCR Extraction from Files - Ends")
        return encoded

    except Exception as e:
        LOGGER.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/centuryAgents/conversationAgent/")
async def conversationAgent(input: str = Form(...), 
    session_id: str = Form(...), 
    file: Optional[List[UploadFile]] = File(None)):
    redis_chat_history = RedisChatMessageHistory(
        session_id=session_id,
        url=redis_url
    )

    if file is not None:
        ocr_data = await ocr_extraction_excel(file)
        response_data = {
            "message": "File uploaded successfully",
            "data": ocr_data,
            "message_type": "LLM",
            "sessionId": session_id,
            }
        return response_data
    else:
        async def generate():
            class StreamCallbackHandler(StreamingStdOutCallbackHandler):
                def __init__(self):
                    self.queue = asyncio.Queue()
    
                async def on_llm_new_token(self, token: str, **kwargs):
                    LOGGER.info("on_llm_new_token function starts")
                    LOGGER.info("Token(Inside on_llm_new_token) = ")
                    LOGGER.info(token)
                    await self.queue.put(token)
                    LOGGER.info("on_llm_new_token function ends")
    
                async def stream(self):
                    LOGGER.info("stream function starts")
                    while True:
                        token = await self.queue.get()
                        LOGGER.info("Token(Inside stream) = ")
                        LOGGER.info(token)
                        if token is None:
                            break
                        yield token
                    LOGGER.info("stream function ends")
    
                async def on_llm_end(self, response, **kwargs):
                    LOGGER.info("on_llm_end function starts")
                    llm_response = response.generations[0][0].text
                    LOGGER.info("llm_response(Inside on_llm_end) = ")
                    LOGGER.info(llm_response)
                    async def submit_order():
                        LOGGER.info("Inside Submit Order Method - Starts")
                        if "comprehensive summary" in llm_response.lower() or "location summary" in llm_response.lower() :
                            payload = {
                                "prompt": """You are an information extraction assistant.  
                                    The input data you will be processing is a response from another Large Language Model. You must identify key entities and their corresponding values, convert it into single JSON object.
                                
                                **Constraints:**
                                    - The final output MUST be a valid JSON object.
                                    - If the Input Data contains Address details like Address Line 1, City, State, Country, Zip Code, Do not process this into array or object. Keep it as it is like key and value.
                                    - If the Input Data contains List of Address details in a single line not like Address Line 1, City, State, Country, Zip Code. Convert that List of single line address details data into list of objects of Address Line 1, City, State, Country, Zip Code under the same name. Do not change the object name.
                                    - DO NOT include any text, explanations, or prose outside of the JSON object.
                                    - If any value from the input data has braces remove it. For example: key : value (sample). Remove the braces and consider key and value alone.
                                    - Do not generate json placeholder like ```json, Return only the json starting and ending with curly braces.
                                    - Do not add extra keys or assumptions.
                                
                                Here is the input data : {llm_res}""".format(llm_res = llm_response),
                                "model": "OpenAI"
                            }

                            response_json = get_llm_content(payload)
                            LOGGER.info("response_json(Inside on_llm_end)")
                            LOGGER.info(response_json)
                            # LOGGER.info(response_json.get("response",""))
                            try:
                                LOGGER.info(type(response_json))
                                inbound_request = json.loads(response_json)
                            except:
                                inbound_request = response_json
                            LOGGER.info(inbound_request)
                            inbound_request["sessionId"] = session_id
                            LOGGER.info(inbound_request)
        
                            headers = {
                                "Content-Type": "application/json"
                            }
                            server_params = {
                            "command": "python",
                            "args": ["E:/agents/Mcp/mcp_servers/process_plan/server.py"]
                            }
                            base_url = "http://prod-llm.excelacomcloud.net:11434"
                            mcp_process = McpClient(base_url)
                            process_plan = await mcp_process.run_agent(llm_response,server_params)
                            LOGGER.info(process_plan)
                            inbound_url = "https://dev-mlaa-g7-product.excelacomcloud.net/centuryInboundService/v1/"
                            inbound_url += process_plan['process_plan_name']
                            
                            # if "comprehensive summary" in llm_response.lower():
                            #     inbound_url = config_loader.get('sales_order_url')
                            #     LOGGER.info(inbound_url)
                            #     start_time = dt.datetime.now()
                                
                            # elif "location summary" in llm_response.lower():
                            #     LOGGER.info("Inside else if for location summary")
                            #     inbound_url = config_loader.get('cpq_sales_order_url')
                            #     start_time = dt.datetime.now()

                            # elif "contract summary" in llm_response.lower():
                            #     LOGGER.info("Inside else if for contract summary")
                            #     inbound_url = "https://dev-mlaa-g7-product.excelacomcloud.net/centuryAgents/runAgent/"
                            #     contract_request = {
                            #         "Billing Frequency": "Annually",
                            #         "Contract Spend Tolerance":275.00,
                            #         "Contract Terms":"14 Months",
                            #         "Discount %":20,
                            #         "Minimum Termination Notice Period":"40 Days",
                            #         "Payment Terms":"Net 50",
                            #         "Penalty":5000.00,
                            #         "Renewal Required?": "No"
                            #     }
                                
                            #     LOGGER.info(response_json)

                            #     contract_request['payload_data'] = {
                            #         "processAction": "complete",
                            #         "entityInstanceId": response_json["Contract Id"],
                            #         "instanceId": "60084849547",
                            #         "parentEntityPCId": 80050000035669,
                            #         "processSpecificAction": "Approve",
                            #         "userProfile": {
                            #             "userName": "Administrator",
                            #             "userTimeZone": "IST",
                            #             "userLocale": "en_US",
                            #             "firstName": "ShaneBoehmB",
                            #             "lastName": "EttieGreenholtG",
                            #             "email": "muralitharan.m@excelacom.in",
                            #             "csUserId": "1197",
                            #             "group": [
                            #                 "1000",
                            #                 "1706337",
                            #                 "1707219",
                            #                 "1707220",
                            #                 "1707221",
                            #                 "1707222",
                            #                 "1707223",
                            #                 "1707224",
                            #                 "1707542",
                            #                 "1707777",
                            #                 "1708141",
                            #                 "1708542",
                            #                 "1709941",
                            #                 "1710305",
                            #                 "1710307",
                            #                 "1710309",
                            #                 "1710311",
                            #                 "1710313",
                            #                 "1710315",
                            #                 "1710623",
                            #                 "1713857",
                            #                 "200",
                            #                 "2631",
                            #                 "3000",
                            #                 "304711",
                            #                 "606236",
                            #                 "606678",
                            #                 "922"
                            #             ]
                            #         }
                            #     }
                            #     inbound_request = {
                            #         "agentId": "90050000220387",
                            #         "data": contract_request,
                            #     }
                            LOGGER.info(inbound_request)
                            inbound_response = requests.post(inbound_url,json=inbound_request,headers=headers)
                            LOGGER.info(inbound_response.text)
                            LOGGER.info(type(inbound_response.text))
                            try:
                                response_string = ''
                                response_json = json.loads(inbound_response.text)
                                LOGGER.info(response_json)
                                if  "comprehensive summary" in llm_response.lower():
                                    
                                    for key,value in response_json.items():
                                        LOGGER.info(value)
                                        LOGGER.info(type(value))
                                        if int(value) > 0:
                                            notify_flag = True
                                            sales_order_id = value
                                        else:
                                            notify_flag = False
                                    end_time = dt.datetime.now()
                                    time_taken = "{:.2f}".format((end_time - start_time).total_seconds())
                                    LOGGER.info(notify_flag)
                                    if notify_flag:
                                        message_data = "\n\nSales Order ID - "+ str(sales_order_id) +"\n\n\nOrder placed in - "+ str(time_taken) + " seconds \n"
                                        notify_payload = {
                                            "message": message_data,
                                            "message_type": "LLM",
                                        }
                                        LOGGER.info(notify_payload)
                                        LOGGER.info(type(notify_payload))
                                        LOGGER.info(session_id)
                                        notify_response_dict = await notify(session_id, notify_payload)   
                                        LOGGER.info('After notify method') 
                                        LOGGER.info(notify_response_dict) 
                                elif "location summary" in llm_response.lower():
                                    notify_payload = {
                                        "message": response_json,
                                        "message_type": "LLM",
                                    }
                                    LOGGER.info(notify_payload)
                                    LOGGER.info(type(notify_payload))
                                    LOGGER.info(session_id)
                                    notify_response_dict = await notify(session_id, notify_payload)   
                                    LOGGER.info('After notify method') 
                                    LOGGER.info(notify_response_dict)    
                                elif "contract summary" in llm_response.lower():
                                    LOGGER.info("Inside contract final")
                                    LOGGER.info(response_json["responseMessage"]["requestProcessId"])
                                    message_str = "Contract Approved"
                                    notify_payload = {
                                        "message": message_str,
                                        "message_type": "LLM",
                                    }
                                    LOGGER.info(notify_payload)
                                    LOGGER.info(type(notify_payload))
                                    LOGGER.info(session_id)
                                    notify_response_dict = await notify(session_id, notify_payload)   
                                    LOGGER.info('After notify method') 
                                    LOGGER.info(notify_response_dict)     
                                
                            except:
                                LOGGER.error(traceback.format_exc())
                                LOGGER.info('Except Class')
                                LOGGER.info(inbound_response.text)
                                
                    asyncio.create_task(submit_order())
                    LOGGER.info("on_llm_end function ends")
    
            callback = StreamCallbackHandler()
            LOGGER.info("callback = ")
            LOGGER.info(callback)
            LOGGER.info("type(callback) = ")
            LOGGER.info(type(callback))
            LOGGER.info(config_loader.get('conversation_model')) 
            llm = ChatOllama(model=config_loader.get('conversation_model'), base_url="http://prod-llm.excelacomcloud.net:11434", callbacks=[callback])
            LOGGER.info("Before Redis connection")
            
            # LOGGER.info("redis_chat_history = ")
            # LOGGER.info(redis_chat_history)
            # LOGGER.info("type(redis_chat_history) = ")
            # LOGGER.info(type(redis_chat_history))

            LOGGER.info("Before Memory")
            empty_history = ChatMessageHistory()
            memory = ConversationBufferWindowMemory(chat_memory=empty_history, k=20, return_messages=True)
            LOGGER.info("Memory = ")
            LOGGER.info(memory)
            LOGGER.info("type(Memory) = ")
            LOGGER.info(type(memory))

            LOGGER.info("Before conversation")
            conversation = ConversationChain(
            llm=llm,
            memory=memory,
            verbose=False
            )
            LOGGER.info("conversation = ")
            LOGGER.info(conversation)
            LOGGER.info("type(conversation) = ")
            LOGGER.info(type(conversation))

            async def producer():
                LOGGER.info("producer function starts")
                await conversation.apredict(input=input)
                await callback.queue.put(None)
                LOGGER.info("producer function ends")
            
            task = asyncio.create_task(producer())
    
            LOGGER.info("Before callback.stream")
            async for token in callback.stream():
                event = {
                "message": token,
                "message_type": "LLM",
                "sessionId": session_id,
                }
                yield f"data: {json.dumps(event)}\n\n"
                LOGGER.info("event(Inside callback.stream()) = ")
                LOGGER.info(event)
            
            LOGGER.info("After callback.stream")
            await task
    
        return StreamingResponse(generate(), media_type="text/plain")


@app.post('/centuryAgents/getLLMResponse/')
def get_llm_content(request: Dict[Any, Any]):
    try:
        LOGGER.info('Get llm content method -Starts')
        llm_endpoint = config_loader.get("openai_endpoint")
        openai_api_key = config_loader.get("openai_api_key")
        llm_source = request['model']
        if llm_source == 'OpenAI':
            payload = {
                "model":"gpt-4",
                "messages": [
                    {
                    "role": "user",
                    "content": str(request['prompt'])
                    }
                ],
                "stream": False
            }
    
            response_value = requests.post(llm_endpoint, json=payload, headers={'api-key': openai_api_key})
            llm_response = json.loads(response_value.text)
            LOGGER.info(llm_response)
            llm_res = llm_response['choices'][0]['message']['content']
        elif llm_source == 'Ollama':
            payload = {
                "prompt": request['prompt'],
                "model": "llama3.3",
                "stream": False
            }
            data = requests.post("http://prod-llm.excelacomcloud.net:11434/api/generate", json=payload)
            response_json = json.loads(data.text)
            LOGGER.info(response_json)
            llm_res = response_json.get("response", "")
        else:
            payload = {
                "prompt": request['prompt'],
                "model": llm_source,
                "stream": False
            }
            data = requests.post("http://prod-llm.excelacomcloud.net:11434/api/generate", json=payload)
            response_json = json.loads(data.text)
            LOGGER.info(response_json)
            llm_res = response_json.get("response", "")
        response_data = {
            "status":"200",
            "llmResponse": llm_res
        }
        try:
            if '{' in llm_res:
                llm_response = json.loads(llm_res)
            else:
                llm_response = str(llm_res)
        except:
            llm_response = str(llm_res)
        LOGGER.info(response_data)
        LOGGER.info('Get llm content method -Ends')
        return llm_response
    except Exception as e:
        LOGGER.error(traceback.format_exc())

@app.post("/centuryAgents/getRedisMessages/")
def get_redis_messages(inputData: RedisMessages):
    try:
        LOGGER.info("Get Redis Messages - Starts")
        redis_chat_history = RedisChatMessageHistory(
            session_id=inputData.sessionId,
            url=redis_url 
        )
        LOGGER.info("redis_chat_history")
        LOGGER.info(redis_chat_history)
        LOGGER.info("type(redis_chat_history)")
        LOGGER.info(type(redis_chat_history))

        LOGGER.info("Before Memory")
        memory = ConversationBufferWindowMemory(chat_memory=redis_chat_history, k=20, return_messages=True)
        LOGGER.info(memory)
        LOGGER.info(memory.chat_memory.messages)

        chat_messages = []

        for message in memory.chat_memory.messages:
            response = {}
            if message.type == 'human':
                response["MESSAGE_TYPE"] = "user"
                response["MESSAGE"] = message.content
            else:
                response["MESSAGE_TYPE"] = "llm"
                response["MESSAGE"] = message.content

            chat_messages.append(response)

        LOGGER.info("Get Redis Messages - Ends")
        return chat_messages
    except:
        LOGGER.error(traceback.format_exc())


async def redis_message_stream(session_id: str):
    try:
        LOGGER.info("Redis message stream method - Starts")
        redis = await aioredis.from_url(redis_url, decode_responses=True)
        pubsub = redis.pubsub()
        await pubsub.subscribe(session_id)

        try:
            async for message in pubsub.listen():
                if message["type"] == "message":
                    data = message["data"]
                    LOGGER.info("Redis message stream method - Ends")
                    yield f"data: {data}\n\n"
        except asyncio.CancelledError:
            await pubsub.unsubscribe(session_id)
            await pubsub.close()
            raise
    except:
        LOGGER.error(traceback.format_exc())

 
@app.get("/centuryAgents/stream/{session_id}")
async def stream(session_id: str):
    return StreamingResponse(redis_message_stream(session_id), media_type="text/event-stream")
 
 
@app.post("/centuryAgents/notify/{session_id}")
async def notify(session_id: str, message: dict = Body(...)):
    try:

        LOGGER.info("Inside notify method - Starts")
        redis = await aioredis.from_url(redis_url, decode_responses=True)
    
        message_to_publish = {**message, "id": str(time.time())}
    
        await redis.publish(session_id, json.dumps(message_to_publish))
        LOGGER.info(f"Published message to {session_id}")
        LOGGER.info(message['message'])
        if 'Order placed in' in message['message']:
            await asyncio.sleep(1)
            redis_chat_history = RedisChatMessageHistory(
                session_id=session_id,
                url=redis_url
            )
            redis_chat_history.add_message(AIMessage(content=message['message']))
            LOGGER.info(redis_chat_history.messages)
        LOGGER.info("Inside notify method - Ends")
        return {"status": "success", "session_id": session_id, "message": message}
    except:
        LOGGER.error(traceback.format_exc())
        return {"status": "failure", "session_id": session_id, "message": message}

@app.post("/centuryAgents/generateSessionId/")
def generate_session_id():
    try:
        unique_id = uuid.uuid4()
        response={
            "status":"Success",
            "session_id": unique_id
        }
        return response
    except Exception as e:
        LOGGER.error(traceback.format_exc())
# Below code to write data from oracle DB into files.
try:
    LOGGER.info("Main started")
    output=startupLoading() # Function to write data into files from oracle DB
    LOGGER.info("Main ended")
except Exception as e:
    LOGGER.error(traceback.format_exc())

